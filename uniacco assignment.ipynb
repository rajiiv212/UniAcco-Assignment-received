{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f44b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.4-py3-none-win_amd64.whl (89.1 MB)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install xgboost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# from xgboost import XGBClassifier\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline \n",
    "\n",
    "## Models\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "!pip install xgboost\n",
    "# from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data_Science_Internship - Dump.csv').drop(['Unnamed: 0'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Agent_id', 'lead_id'], axis=1)\n",
    "\n",
    "# set the columns to consider for null values\n",
    "columns_to_consider = ['lost_reason', 'budget', 'lease', 'movein','source', 'source_city', 'source_country', \n",
    "                       'utm_medium','des_city', 'des_country']\n",
    "\n",
    "# set the minimum number of non-null values required for each row to be kept\n",
    "thresh = len(columns_to_consider) / 2\n",
    "\n",
    "# remove rows where 50% of the columns being considered have null values\n",
    "df = df.dropna(subset=columns_to_consider, thresh=thresh)\n",
    "\n",
    "search_string = '9b2d5b4678781e53038e91ea5324530a03f27dc1d0e5f6c9bc9d493a23be9de0' \n",
    "\n",
    "# Count the number of occurrences of the string in the DataFrame\n",
    "count = (df == search_string).sum().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The string '{search_string}' occurs {count} times in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126fd370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with status other than 'WON' or 'LOST'\n",
    "df = df[df['status'].isin(['WON', 'LOST'])]\n",
    "\n",
    "# replace long strings with NaN\n",
    "cols_to_exclude = ['Agent_id'] # exclude the Agent_id column\n",
    "df.loc[:, ~df.columns.isin(cols_to_exclude)] = df.loc[:, ~df.columns.isin(cols_to_exclude)].apply(lambda x: x.mask(x.apply(lambda y: str(y) == search_string)))\n",
    "\n",
    "null_perc = df.isnull().sum() / len(df) * 100\n",
    "null_perc = null_perc.fillna(\"No Null Values\")\n",
    "\n",
    "print('The percentage of NULL Values in differenct columns are:')\n",
    "null_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c4dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9caeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will take care of null values in each column one by one, starting from the column \n",
    "# with highest percentage of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['room_type'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since most people opt for an 'Ensuite\" room and almost 55% values are Ensuite in this column,\n",
    "# we can use mode imputation.\n",
    "df['room_type'] = df['room_type'].fillna(\"Ensuite\")\n",
    "#df = df.drop(['room_type'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['movein'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a6d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['movein'] = df['movein'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c44504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source_city'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce2a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source_city'] = df['source_city'].fillna(\"Not_disclosed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9face39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source_country'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source_country'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce9cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = df['source_country'].mode()[0]\n",
    "df['source_country'] = df['source_country'].fillna(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c67970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211683cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078379a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = df['source'].mode()[0]\n",
    "df['source'] = df['source'].fillna(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['budget'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['budget'] = df['budget'].fillna(\"Not_specified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e1a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['utm_medium'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = df['utm_medium'].mode()[0]\n",
    "df['utm_medium'] = df['utm_medium'].fillna(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca22b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lost_reason'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lost_reason'] = df['lost_reason'].fillna(\"lead_won\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d893324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lease'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lease'] = df['lease'].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b917e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['des_city'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['des_city'] = df['des_city'].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be917939",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['des_country'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62aa6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = df['des_country'].mode()[0]\n",
    "df['des_country'] = df['des_country'].fillna(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aebef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['utm_source'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4babae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = df['utm_source'].mode()[0]\n",
    "df['utm_source'] = df['utm_source'].fillna(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41709c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include=['object']):\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905ea662",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['status'], axis=1)\n",
    "y = df['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f68dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, y_test = train_test_split(X, y, test_size=0.33, stratify = y, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a24b0",
   "metadata": {},
   "source": [
    "##### Balancing the dataset using SMOTE method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bbf63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smt = SMOTE(random_state=42)\n",
    "\n",
    "X_res, y_res = smt.fit_resample(X_train, Y_train)\n",
    "\n",
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72799632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing sklearn StandardScaler class which is for Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler() # creating an instance of the class object\n",
    "X_res_scaled = pd.DataFrame(sc.fit_transform(X_res), columns=X_res.columns)  #fit and transforming StandardScaler the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g6_BDUzXyvwC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "g6_BDUzXyvwC",
    "outputId": "687d4c54-4e26-4c98-844f-f9733887a1ca"
   },
   "outputs": [],
   "source": [
    "from sklearn .metrics import f1_score\n",
    "\n",
    "sgd = linear_model.SGDClassifier(max_iter=5, tol=None)\n",
    "sgd.fit(X_res_scaled, y_res)\n",
    "y_pred = sgd.predict(X_test)\n",
    "score_sgd = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_res_scaled, y_res)\n",
    "y_pred = logreg.predict(X_test)\n",
    "score_log = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3) \n",
    "knn.fit(X_res_scaled, y_res)  \n",
    "y_pred = knn.predict(X_test)  \n",
    "score_knn = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "gaussian = GaussianNB() \n",
    "gaussian.fit(X_res_scaled, y_res)  \n",
    "y_pred = gaussian.predict(X_test)\n",
    "score_gaussian = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "perceptron = Perceptron(max_iter=100)\n",
    "perceptron.fit(X_res_scaled, y_res)\n",
    "y_pred = perceptron.predict(X_test)\n",
    "score_perceptron = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "decision_tree = DecisionTreeClassifier() \n",
    "decision_tree.fit(X_res_scaled, y_res)  \n",
    "y_pred = decision_tree.predict(X_test)  \n",
    "score_decision_tree = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_res_scaled, y_res)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "score_random_forest = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "XGBoost = XGBClassifier()\n",
    "XGBoost.fit(X_res_scaled, y_res)\n",
    "y_pred = XGBoost.predict(X_test)\n",
    "score_XGBoost = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLPClassifier = MLPClassifier()\n",
    "MLPClassifier.fit(X_res_scaled, y_res)\n",
    "y_pred = MLPClassifier.predict(X_test)\n",
    "score_MLPClassifier = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# comparing all the models\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['KNN', 'Logistic Regression','Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent','Decision Tree', 'XG Boost', 'Neural Network'],\n",
    "    'Weighted F1': [score_knn, score_log, score_random_forest, score_gaussian, score_perceptron, score_sgd, \n",
    "              score_decision_tree, score_XGBoost, score_MLPClassifier]})\n",
    "result_df = results.sort_values(by='Weighted F1', ascending=False)\n",
    "result_df = result_df.set_index('Weighted F1')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be01894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn .metrics import recall_score\n",
    "\n",
    "sgd = linear_model.SGDClassifier(max_iter=5, tol=None)\n",
    "sgd.fit(X_res_scaled, y_res)\n",
    "y_pred = sgd.predict(X_test)\n",
    "score_sgd = recall_score(y_test, y_pred)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_res_scaled, y_res)\n",
    "y_pred = logreg.predict(X_test)\n",
    "score_log = recall_score(y_test, y_pred)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3) \n",
    "knn.fit(X_res_scaled, y_res)  \n",
    "y_pred = knn.predict(X_test)  \n",
    "score_knn = recall_score(y_test, y_pred)\n",
    "\n",
    "gaussian = GaussianNB() \n",
    "gaussian.fit(X_res_scaled, y_res)  \n",
    "y_pred = gaussian.predict(X_test)\n",
    "score_gaussian = recall_score(y_test, y_pred)\n",
    "\n",
    "perceptron = Perceptron(max_iter=100)\n",
    "perceptron.fit(X_res_scaled, y_res)\n",
    "y_pred = perceptron.predict(X_test)\n",
    "score_perceptron = recall_score(y_test, y_pred)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier() \n",
    "decision_tree.fit(X_res_scaled, y_res)  \n",
    "y_pred = decision_tree.predict(X_test)  \n",
    "score_decision_tree = recall_score(y_test, y_pred)\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_res_scaled, y_res)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "score_random_forest = recall_score(y_test, y_pred)\n",
    "\n",
    "XGBoost = XGBClassifier()\n",
    "XGBoost.fit(X_res_scaled, y_res)\n",
    "y_pred = XGBoost.predict(X_test)\n",
    "score_XGBoost = recall_score(y_test, y_pred)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLPClassifier = MLPClassifier()\n",
    "MLPClassifier.fit(X_res_scaled, y_res)\n",
    "y_pred = MLPClassifier.predict(X_test)\n",
    "score_MLPClassifier = recall_score(y_test, y_pred)\n",
    "\n",
    "# comparing all the models\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['KNN', 'Logistic Regression','Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent','Decision Tree', 'XG Boost', 'Neural Network'],\n",
    "    'Recall': [score_knn, score_log, score_random_forest, score_gaussian, score_perceptron, score_sgd, \n",
    "              score_decision_tree, score_XGBoost, score_MLPClassifier]})\n",
    "result_df = results.sort_values(by='Recall', ascending=False)\n",
    "result_df = result_df.set_index('Recall')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70472be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLPClassifier = MLPClassifier()\n",
    "MLPClassifier.fit(X_res_scaled, y_res)\n",
    "y_pred = MLPClassifier.predict(X_test)\n",
    "y_prob = MLPClassifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,), (20,), (30,)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# Define the grid search object\n",
    "rand_search = RandomizedSearchCV(MLPClassifier, param_distributions=param_grid, cv=5, scoring='recall')\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "rand_search.fit(X_res_scaled, y_res)\n",
    "\n",
    "# Get the best model and evaluate on the test data\n",
    "best_mlp = rand_search.best_estimator_\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "y_prob = best_mlp.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6308a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Print evaluation metrics\n",
    "print('Accuracy: {:.4f}'.format(accuracy))\n",
    "print('Precision: {:.4f}'.format(precision))\n",
    "print('Recall: {:.4f}'.format(recall))\n",
    "print('F1 score: {:.4f}'.format(f1))\n",
    "print('AUC: {:.4f}'.format(auc))\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('True negative: {}'.format(tn))\n",
    "print('False positive: {}'.format(fp))\n",
    "print('False negative: {}'.format(fn))\n",
    "print('True positive: {}'.format(tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for the test set\n",
    "y_pred_proba = best_mlp.predict_proba(X)[:, 1]\n",
    "\n",
    "# Convert probabilities to scores between 0 to 100\n",
    "lead_score = (y_pred_proba * 100).round(0)\n",
    "\n",
    "# Add the 'lead_score' column to the original dataframe\n",
    "df['lead_score'] = lead_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e8aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251bd5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daffa5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
